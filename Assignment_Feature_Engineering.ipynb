{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "- A parameter is a numerical value that represents a characteristic of a population or controls the behavior of a machine learning model. In machine learning, parameters are learned automatically during training and help the model make predictions. Examples of parameters include weights and bias in a linear regression or neural network.\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "- Correlation is a statistical measure that describes the strength and direction of the relationship between two variables. It indicates how one variable changes with respect to another. The value of correlation lies between –1 and +1, where +1 indicates a strong positive relationship, –1 indicates a strong negative relationship, and 0 indicates no relationship.\n",
        "\n",
        " What does negative correlation mean?\n",
        "\n",
        "- Negative correlation means that when the value of one variable increases, the value of the other variable decreases. This indicates an inverse relationship between the two variables. For example, as the speed of a vehicle increases, the time taken to cover a fixed distance decreases.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "- Machine Learning is a branch of artificial intelligence that enables systems to learn patterns from data and make predictions or decisions without being explicitly programmed. The main components of machine learning include data, features, a model, a loss function to measure errors, an optimizer to reduce the loss, and evaluation metrics to assess performance.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "- The loss value measures how far the predicted output of a model is from the actual output. A lower loss value indicates better model performance, while a higher loss value shows poor predictions. During training, the goal is to minimize the loss so that the model learns accurate patterns from the data.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "\n",
        "- Continuous variables are numerical variables that can take any value within a given range, such as height, weight, or temperature. Categorical variables represent distinct groups or labels, such as gender, city, or product category. These variables usually need special handling in machine learning models.\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "- Categorical variables are handled by converting them into numerical form so that machine learning algorithms can process them. Common techniques include Label Encoding, where categories are converted into numbers, One-Hot Encoding, where each category is represented as a binary column, and Ordinal Encoding, which preserves an order among categories.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "- Training and testing datasets are used to evaluate a machine learning model’s performance. The training dataset is used to teach the model patterns and relationships, while the testing dataset is used to check how well the trained model performs on unseen data. This helps ensure the model generalizes well.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "- sklearn.preprocessing is a module in the Scikit-learn library that provides tools for data preprocessing. It includes methods for scaling, normalization, encoding categorical variables, and handling missing values. Preprocessing ensures that data is in a suitable format for machine learning models.\n",
        "\n",
        "9. What is a test set?\n",
        "\n",
        "- A test set is a portion of the dataset that is reserved only for evaluating the final trained model. It is not used during training. The test set helps measure how well the model performs on new and unseen data, which reflects real-world performance.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "- In Python, data is commonly split using the train_test_split() function from the sklearn.model_selection module. This function divides the dataset into training and testing subsets based on a specified ratio, ensuring random and unbiased splitting.\n",
        "\n",
        " How do you approach a Machine Learning problem?\n",
        "\n",
        "- A machine learning problem is approached by first understanding the problem statement and objectives. Then data is collected and explored using EDA. After preprocessing and feature selection, the data is split into training and testing sets. A suitable model is chosen, trained, evaluated, and optimized before deployment.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "- Exploratory Data Analysis (EDA) is performed to understand the structure and quality of the data. It helps identify missing values, outliers, trends, correlations, and patterns. Performing EDA ensures better feature selection, improved model accuracy, and reduced chances of errors during training.\n",
        "\n",
        "12. How can you find correlation between variables in Python?\n",
        "\n",
        "- Correlation between variables in Python can be calculated using the .corr() method in pandas. It helps determine the relationship between multiple variables or between two specific variables, making it useful during EDA to understand feature relationships.\n",
        "\n",
        "13. What is causation? Explain the difference between correlation and causation with an example.\n",
        "\n",
        "- Causation means that one event directly causes another event to occur. Correlation, on the other hand, only indicates a relationship but does not imply cause. For example, ice cream sales and drowning incidents may be correlated because both increase in summer, but ice cream sales do not cause drowning.\n",
        "\n",
        "14. What is an Optimizer? What are different types of optimizers?\n",
        "\n",
        "- An optimizer is an algorithm used to update model parameters in order to minimize the loss function. Common optimizers include Gradient Descent, Stochastic Gradient Descent (SGD), Adam, and RMSprop. These optimizers help the model learn efficiently by adjusting weights during training.\n",
        "\n",
        "15. What is sklearn.linear_model?\n",
        "\n",
        "- sklearn.linear_model is a module in Scikit-learn that provides linear models for regression and classification tasks. It includes algorithms such as Linear Regression, Logistic Regression, Ridge, and Lasso, which are widely used for predictive modeling.\n",
        "\n",
        "16. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "- The model.fit() method trains the machine learning model using the training data. It requires input features (X) and target labels (y) as arguments. During fitting ,the model learns patterns by adjusting its parameters to minimize the loss function.\n",
        "\n",
        "17. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "- The model.predict() method is used to generate predictions using a trained model. It takes input feature data as an argument and returns predicted output values. This method is commonly used on test data or new unseen data.\n",
        "\n",
        "18. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "- Feature scaling is the process of bringing all numerical features to a similar scale. It helps machine learning algorithms perform better and faster by preventing features with large values from dominating smaller ones. Scaling is especially important for distance-based algorithms.\n",
        "\n",
        "19. How do we perform scaling in Python?\n",
        "\n",
        "- Feature scaling in Python is performed using preprocessing classes such as StandardScaler and MinMaxScaler from sklearn.preprocessing. These methods transform numerical data into standardized or normalized form before model training.\n",
        "\n",
        "20. What is sklearn.preprocessing?\n",
        "\n",
        "- `sklearn.preprocessing` is a module in the Scikit-learn library that provides tools for preparing raw data before applying machine learning algorithms. It includes techniques such as feature scaling, normalization, standardization, and encoding of categorical variables. By transforming data into a suitable numerical format and bringing features to a common scale, `sklearn.preprocessing` helps improve model performance, training stability, and accuracy.\n",
        "\n",
        "\n",
        "21. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "- In Python, data is split into training and testing sets using the train_test_split() function from the sklearn.model_selection module. This function divides the dataset into two parts, where the training set is used to train the machine learning model and the testing set is used to evaluate its performance on unseen data. By specifying parameters such as test_size, we can control how much data is reserved for testing, and the split is done randomly to avoid bias. This approach helps ensure that the model generalizes well and does not overfit the training data.\n",
        "\n",
        "\n",
        "22. Explain data encoding.\n",
        "\n",
        "- Data encoding is the process of converting categorical data into numerical format so that machine learning algorithms can process it. Encoding techniques such as Label Encoding and One-Hot Encoding are commonly used to represent categorical variables effectively in models.\n",
        "\n"
      ],
      "metadata": {
        "id": "mxxhGENskcRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGCll56DkYwk"
      },
      "outputs": [],
      "source": []
    }
  ]
}